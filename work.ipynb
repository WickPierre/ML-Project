{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "class Config:\n",
    "    data_root = 'ml-intensive-yandex-academy-spring-2025/human_poses_data'\n",
    "    img_train_dir = os.path.join(data_root, 'img_train')\n",
    "    categories_file = os.path.join(data_root, 'activity_categories.csv')\n",
    "    train_answers_file = os.path.join(data_root, 'train_answers.csv')\n",
    "    img_size = (224, 224)\n",
    "    batch_size = 32\n",
    "    num_workers = 0\n",
    "    test_size = 0.15\n",
    "    val_size = 0.15\n",
    "    random_state = 42\n",
    "    num_classes = 20\n",
    "    lr = 0.001\n",
    "    weight_decay = 1e-4\n",
    "    epochs = 50\n",
    "    flip_prob = 0.5\n",
    "    save_dir = 'saved_models_densenet'\n",
    "    growth_rate = 12\n",
    "    block_config = (4, 4, 4)\n",
    "    bn_size = 4\n",
    "    drop_rate = 0.2\n",
    "\n",
    "class DenseLayer(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate, bn_size, drop_rate):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.BatchNorm2d(in_channels)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_channels, bn_size * growth_rate, kernel_size=1, bias=False)\n",
    "        \n",
    "        self.norm2 = nn.BatchNorm2d(bn_size * growth_rate)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(bn_size * growth_rate, growth_rate, kernel_size=3, padding=1, bias=False)\n",
    "        \n",
    "        self.drop_rate = drop_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        new_features = self.conv1(self.relu1(self.norm1(x)))\n",
    "        new_features = self.conv2(self.relu2(self.norm2(new_features)))\n",
    "        if self.drop_rate > 0:\n",
    "            new_features = F.dropout(new_features, p=self.drop_rate, training=self.training)\n",
    "        return torch.cat([x, new_features], 1)\n",
    "\n",
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, num_layers, in_channels, growth_rate, bn_size, drop_rate):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for i in range(num_layers):\n",
    "            layer = DenseLayer(\n",
    "                in_channels + i * growth_rate,\n",
    "                growth_rate,\n",
    "                bn_size,\n",
    "                drop_rate\n",
    "            )\n",
    "            layers.append(layer)\n",
    "        self.block = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class Transition(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.norm = nn.BatchNorm2d(in_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(self.relu(self.norm(x)))\n",
    "        return self.pool(x)\n",
    "\n",
    "class DenseNetFromScratch(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.features = nn.Sequential()\n",
    "        \n",
    "        self.features.add_module('conv0', nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False))\n",
    "        self.features.add_module('norm0', nn.BatchNorm2d(64))\n",
    "        self.features.add_module('relu0', nn.ReLU(inplace=True))\n",
    "        self.features.add_module('pool0', nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "        \n",
    "        num_features = 64\n",
    "        for i, num_layers in enumerate(config.block_config):\n",
    "            block = DenseBlock(\n",
    "                num_layers=num_layers,\n",
    "                in_channels=num_features,\n",
    "                growth_rate=config.growth_rate,\n",
    "                bn_size=config.bn_size,\n",
    "                drop_rate=config.drop_rate\n",
    "            )\n",
    "            self.features.add_module(f'denseblock{i+1}', block)\n",
    "            num_features += num_layers * config.growth_rate\n",
    "            \n",
    "            if i != len(config.block_config)-1:\n",
    "                trans = Transition(num_features, num_features // 2)\n",
    "                self.features.add_module(f'transition{i+1}', trans)\n",
    "                num_features = num_features // 2\n",
    "        \n",
    "        self.features.add_module('norm_final', nn.BatchNorm2d(num_features))\n",
    "        self.features.add_module('relu_final', nn.ReLU(inplace=True))\n",
    "        self.features.add_module('avg_pool', nn.AdaptiveAvgPool2d((1, 1)))\n",
    "        self.classifier = nn.Linear(num_features, config.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.classifier(x)\n",
    "\n",
    "class HumanPoseDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform=None):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.label_map = pd.read_csv(Config.categories_file).set_index('id')['category'].to_dict()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_id = str(row['img_id']).strip()\n",
    "        label = row['target_feature']\n",
    "        img_path = os.path.join(self.img_dir, f\"{img_id}.jpg\")\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {img_path}: {str(e)}\")\n",
    "            image = Image.new('RGB', Config.img_size)\n",
    "            \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "def get_transforms(config, train=True):\n",
    "    base_transforms = [\n",
    "        transforms.Resize(config.img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]\n",
    "    \n",
    "    if train:\n",
    "        augmentations = [\n",
    "            transforms.RandomHorizontalFlip(config.flip_prob),\n",
    "            transforms.RandomRotation(15),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "        ]\n",
    "        return transforms.Compose(augmentations + base_transforms)\n",
    "    return transforms.Compose(base_transforms)\n",
    "\n",
    "def load_data(config):\n",
    "    try:\n",
    "        print(\"\\n[1/4] Загрузка данных...\")\n",
    "        train_df = pd.read_csv(config.train_answers_file)\n",
    "        print(f\"Пример данных:\\n{train_df.head()}\")\n",
    "        \n",
    "        print(\"\\n[2/4] Валидация данных...\")\n",
    "        train_df = train_df.dropna()\n",
    "        print(f\"Данных после очистки: {len(train_df)}\")\n",
    "        \n",
    "        print(\"\\n[3/4] Проверка изображений...\")\n",
    "        existing_images = {f.split('.')[0] for f in os.listdir(config.img_train_dir)}\n",
    "        print(f\"Найдено изображений: {len(existing_images)}\")\n",
    "        \n",
    "        train_df = train_df[train_df['img_id'].astype(str).isin(existing_images)]\n",
    "        print(f\"Данных после фильтрации: {len(train_df)}\")\n",
    "        \n",
    "        print(\"\\n[4/4] Разделение данных...\")\n",
    "        train_df, test_val_df = train_test_split(\n",
    "            train_df,\n",
    "            test_size=config.test_size + config.val_size,\n",
    "            stratify=train_df['target_feature'],\n",
    "            random_state=config.random_state\n",
    "        )\n",
    "        val_df, test_df = train_test_split(\n",
    "            test_val_df,\n",
    "            test_size=config.test_size/(config.test_size + config.val_size),\n",
    "            stratify=test_val_df['target_feature'],\n",
    "            random_state=config.random_state\n",
    "        )\n",
    "        \n",
    "        return (\n",
    "            HumanPoseDataset(train_df, config.img_train_dir, get_transforms(config, True)),\n",
    "            HumanPoseDataset(val_df, config.img_train_dir, get_transforms(config, False)),\n",
    "            HumanPoseDataset(test_df, config.img_train_dir, get_transforms(config, False))\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"\\nData loading failed: {str(e)}\")\n",
    "        return None, None, None\n",
    "\n",
    "class PoseTrainer:\n",
    "    def __init__(self, config, device):\n",
    "        self.config = config\n",
    "        self.device = device\n",
    "        self.best_metric = 0\n",
    "        self.train_set, self.val_set, self.test_set = load_data(config)\n",
    "        \n",
    "        if not all([self.train_set, self.val_set, self.test_set]):\n",
    "            raise RuntimeError(\"Data loading failed\")\n",
    "            \n",
    "        self._init_dataloaders()\n",
    "        self.model = DenseNetFromScratch(config).to(device)\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            self.model.parameters(),\n",
    "            lr=config.lr,\n",
    "            weight_decay=config.weight_decay\n",
    "        )\n",
    "        self.scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            self.optimizer,\n",
    "            max_lr=config.lr,\n",
    "            epochs=config.epochs,\n",
    "            steps_per_epoch=len(self.train_loader)\n",
    "        )\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def _init_dataloaders(self):\n",
    "        self.train_loader = DataLoader(\n",
    "            self.train_set,\n",
    "            batch_size=self.config.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.config.num_workers,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        self.val_loader = DataLoader(\n",
    "            self.val_set,\n",
    "            batch_size=self.config.batch_size,\n",
    "            num_workers=self.config.num_workers,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        self.test_loader = DataLoader(\n",
    "            self.test_set,\n",
    "            batch_size=self.config.batch_size,\n",
    "            num_workers=self.config.num_workers,\n",
    "            pin_memory=True\n",
    "        )\n",
    "\n",
    "    def train(self):\n",
    "        os.makedirs(self.config.save_dir, exist_ok=True)\n",
    "        history = {'train_loss': [], 'val_loss': [], 'val_acc': [], 'val_f1': []}\n",
    "        \n",
    "        for epoch in range(self.config.epochs):\n",
    "            print(f\"\\nEpoch {epoch+1}/{self.config.epochs}\")\n",
    "            train_loss = self.train_epoch()\n",
    "            val_metrics = self.evaluate(self.val_loader)\n",
    "            \n",
    "            history['train_loss'].append(train_loss)\n",
    "            history['val_loss'].append(val_metrics['loss'])\n",
    "            history['val_acc'].append(val_metrics['accuracy'])\n",
    "            history['val_f1'].append(val_metrics['f1'])\n",
    "            \n",
    "            print(f\"Train Loss: {train_loss:.4f}\")\n",
    "            print(f\"Val Loss: {val_metrics['loss']:.4f}\")\n",
    "            print(f\"Val Acc: {val_metrics['accuracy']:.4f}\")\n",
    "            print(f\"Val F1: {val_metrics['f1']:.4f}\")\n",
    "            print(f\"LR: {self.optimizer.param_groups[0]['lr']:.2e}\")\n",
    "            \n",
    "            # Сохранение после каждой эпохи\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': self.model.state_dict(),\n",
    "                'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                'metrics': val_metrics\n",
    "            }, os.path.join(self.config.save_dir, f'checkpoint_epoch_{epoch+1}.pth'))\n",
    "            \n",
    "            if val_metrics['f1'] > self.best_metric:\n",
    "                self.best_metric = val_metrics['f1']\n",
    "                torch.save(self.model.state_dict(), \n",
    "                         os.path.join(self.config.save_dir, 'best_model.pth'))\n",
    "        \n",
    "        self.plot_training(history)\n",
    "        return history\n",
    "\n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with tqdm(\n",
    "            self.train_loader, \n",
    "            desc='Training', \n",
    "            leave=False, \n",
    "            dynamic_ncols=True,\n",
    "            unit='batch',\n",
    "            bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}{postfix}]'\n",
    "        ) as progress_bar:\n",
    "            \n",
    "            for images, labels in progress_bar:\n",
    "                images = images.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                self.scheduler.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "                all_preds.extend(preds)\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                \n",
    "                batch_f1 = f1_score(labels.cpu().numpy(), preds, average='weighted')\n",
    "                \n",
    "                progress_bar.set_postfix({\n",
    "                    'loss': f'{loss.item():.3f}',\n",
    "                    'f1': f'{batch_f1:.3f}'\n",
    "                })\n",
    "        \n",
    "        epoch_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "        return total_loss / len(self.train_loader), epoch_f1\n",
    "\n",
    "    def evaluate(self, loader):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in loader:\n",
    "                images = images.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                total_loss += loss.item()\n",
    "                all_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                \n",
    "        return {\n",
    "            'loss': total_loss / len(loader),\n",
    "            'accuracy': np.mean(np.array(all_preds) == np.array(all_labels)),\n",
    "            'f1': f1_score(all_labels, all_preds, average='weighted')\n",
    "        }\n",
    "\n",
    "    def plot_training(self, history):\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.plot(history['train_loss'], label='Train Loss')\n",
    "        plt.plot(history['val_loss'], label='Val Loss')\n",
    "        plt.title('Loss Evolution')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "        plt.title('Accuracy Evolution')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.plot(history['val_f1'], label='Validation F1-Score')\n",
    "        plt.title('F1-Score Evolution')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('F1-Score')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(self.config.save_dir, 'training_progress.png'))\n",
    "        plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    config = Config()\n",
    "    \n",
    "    print(\"Path checks:\")\n",
    "    print(\"Categories file:\", os.path.exists(config.categories_file))\n",
    "    print(\"Train answers:\", os.path.exists(config.train_answers_file))\n",
    "    print(\"Image dir:\", os.path.exists(config.img_train_dir))\n",
    "    print(f\"\\nUsing device: {device}\")\n",
    "    \n",
    "    try:\n",
    "        trainer = PoseTrainer(config, device)\n",
    "        history = trainer.train()\n",
    "    except Exception as e:\n",
    "        print(f\"\\nTraining failed: {e}\")\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Конфигурация ===\n",
    "class Config:\n",
    "    img_size = (224, 224)\n",
    "    num_classes = 20\n",
    "    batch_size = 32\n",
    "\n",
    "    # Обновить пути, для тестирования модели\n",
    "\n",
    "    test_dir = '??'\n",
    "    checkpoint_path = '??'\n",
    "    growth_rate = 12\n",
    "    block_config = (4, 4, 4)\n",
    "    bn_size = 4\n",
    "    drop_rate = 0.2\n",
    "\n",
    "class DenseLayer(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate, bn_size, drop_rate):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.BatchNorm2d(in_channels)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_channels, bn_size * growth_rate, kernel_size=1, bias=False)\n",
    "        self.norm2 = nn.BatchNorm2d(bn_size * growth_rate)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(bn_size * growth_rate, growth_rate, kernel_size=3, padding=1, bias=False)\n",
    "        self.drop_rate = drop_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        new_features = self.conv1(self.relu1(self.norm1(x)))\n",
    "        new_features = self.conv2(self.relu2(self.norm2(new_features)))\n",
    "        if self.drop_rate > 0:\n",
    "            new_features = nn.functional.dropout(new_features, p=self.drop_rate, training=self.training)\n",
    "        return torch.cat([x, new_features], 1)\n",
    "\n",
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, num_layers, in_channels, growth_rate, bn_size, drop_rate):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for i in range(num_layers):\n",
    "            layer = DenseLayer(\n",
    "                in_channels + i * growth_rate,\n",
    "                growth_rate,\n",
    "                bn_size,\n",
    "                drop_rate\n",
    "            )\n",
    "            layers.append(layer)\n",
    "        self.block = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class Transition(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.norm = nn.BatchNorm2d(in_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(self.relu(self.norm(x)))\n",
    "        return self.pool(x)\n",
    "\n",
    "class DenseNetFromScratch(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential()\n",
    "        self.features.add_module('conv0', nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False))\n",
    "        self.features.add_module('norm0', nn.BatchNorm2d(64))\n",
    "        self.features.add_module('relu0', nn.ReLU(inplace=True))\n",
    "        self.features.add_module('pool0', nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "        \n",
    "        num_features = 64\n",
    "        for i, num_layers in enumerate(config.block_config):\n",
    "            block = DenseBlock(\n",
    "                num_layers=num_layers,\n",
    "                in_channels=num_features,\n",
    "                growth_rate=config.growth_rate,\n",
    "                bn_size=config.bn_size,\n",
    "                drop_rate=config.drop_rate\n",
    "            )\n",
    "            self.features.add_module(f'denseblock{i+1}', block)\n",
    "            num_features += num_layers * config.growth_rate\n",
    "            \n",
    "            if i != len(config.block_config)-1:\n",
    "                trans = Transition(num_features, num_features // 2)\n",
    "                self.features.add_module(f'transition{i+1}', trans)\n",
    "                num_features = num_features // 2\n",
    "        \n",
    "        self.features.add_module('norm_final', nn.BatchNorm2d(num_features))\n",
    "        self.features.add_module('relu_final', nn.ReLU(inplace=True))\n",
    "        self.features.add_module('avg_pool', nn.AdaptiveAvgPool2d((1, 1)))\n",
    "        self.classifier = nn.Linear(num_features, config.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.classifier(x)\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = sorted(\n",
    "            [f for f in os.listdir(root_dir) if f.lower().endswith(('.jpg', '.png'))],\n",
    "            key=lambda x: int(x.split('.')[0])\n",
    "        )\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.root_dir, img_name)\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except:\n",
    "            image = Image.new('RGB', Config.img_size)\n",
    "            \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return img_name, image\n",
    "\n",
    "config = Config()\n",
    "model = DenseNetFromScratch(config)\n",
    "\n",
    "# Загрузка чекпоинта\n",
    "checkpoint = torch.load(config.checkpoint_path, map_location='cpu')\n",
    "model.load_state_dict(checkpoint['model_state_dict'], strict=True)\n",
    "model.eval()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(config.img_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_dataset = TestDataset(config.test_dir, transform=test_transform)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "predictions = []\n",
    "image_ids = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for filenames, images in tqdm(test_loader, desc=\"Predicting\"):\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "        image_ids.extend(filenames)\n",
    "\n",
    "# Формирование submission\n",
    "submission_df = pd.DataFrame({\n",
    "    'ID': [os.path.splitext(fname)[0] for fname in image_ids],\n",
    "    'target': predictions\n",
    "})\n",
    "\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "print(f\"Submission saved with {submission_df['target'].nunique()} unique classes\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
